{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c8b28c",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Graphcore Ltd. All rights reserved.\n",
    "\n",
    "# DFT dataset generation using PySCF IPU\n",
    "\n",
    "This notebook shows how to generate DFT datasets on the Graphcore IPU based on\n",
    "\"PySCFIPU: Repurposing Density Functional Theory to Suit Deep Learning\", Mathiasen et al, (SynS & ML) Workshop, ICML 2023\n",
    "\n",
    "https://icml.cc/virtual/2023/28485\n",
    "\n",
    "Density Functional Theory (DFT) accurately predicts the properties of molecules given their atom types and positions,\n",
    "and often serves as ground truth for molecular property prediction tasks.\n",
    "Research in other areas of machine learning has shown that generalisation performance \n",
    "of Neural Networks tends to improve with increased dataset size, however, \n",
    "the computational cost of DFT has limited the size of DFT datasets.\n",
    "\n",
    "PySCF_IPU allowed us to create QM10X, a dataset with 100 million conformers, in 3000 IPU-hours.\n",
    "\n",
    "This notebook, running on 4 IPUs on Paperspace, creates 100K conformers in about 1 hour;\n",
    "it can be run on multiple 16-IPU systems (paid instances) to generate the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5faf299",
   "metadata": {},
   "source": [
    "Install `pyscf-ipu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54d5a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T17:51:55.470021Z",
     "iopub.status.busy": "2023-09-19T17:51:55.469829Z",
     "iopub.status.idle": "2023-09-19T17:52:24.963815Z",
     "shell.execute_reply": "2023-09-19T17:52:24.962817Z",
     "shell.execute_reply.started": "2023-09-19T17:51:55.469990Z"
    }
   },
   "outputs": [],
   "source": [
    "# PySCF IPU dependencies \n",
    "%pip install -e \"..[ipu]\"\n",
    "print('install done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f39a33",
   "metadata": {},
   "source": [
    "# Download and preprocess GDB 11 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c260e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T14:57:45.437550Z",
     "iopub.status.busy": "2023-09-19T14:57:45.437267Z",
     "iopub.status.idle": "2023-09-19T14:57:45.450704Z",
     "shell.execute_reply": "2023-09-19T14:57:45.449995Z",
     "shell.execute_reply.started": "2023-09-19T14:57:45.437519Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "gdb_filename = \"./data/gdb11_size09.smi\"\n",
    "out_filename = gdb_filename.replace(\".smi\", \"_sorted.csv\")\n",
    "\n",
    "loaded = os.path.exists(out_filename) and os.path.getsize(out_filename) == 6985727\n",
    "\n",
    "if loaded:\n",
    "  print(f'Found {out_filename}')\n",
    "else:\n",
    "  print(f'Did not find {out_filename}, or size was wrong')\n",
    "\n",
    "  # Download and extract GDB11 dataset.\n",
    "  !mkdir -p ./data\n",
    "  !wget -p -O ./data/gdb11.tgz https://zenodo.org/record/5172018/files/gdb11.tgz\\?download\\=1\n",
    "  !tar -xvf ./data/gdb11.tgz --directory ./gdb/\n",
    "\n",
    "  from  gdb import sortgdb\n",
    "\n",
    "  # Filter & sort GDB11 dataset (size 9).\n",
    "  gdb_sorted = sortgdb.sort_gdb(gdb_filename, keep_only_atoms_count=9)\n",
    "  # Save output as csv.\n",
    "  gdb_sorted.to_csv(out_filename, index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da90c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T14:57:47.169997Z",
     "iopub.status.busy": "2023-09-19T14:57:47.169786Z",
     "iopub.status.idle": "2023-09-19T14:57:47.954940Z",
     "shell.execute_reply": "2023-09-19T14:57:47.953881Z",
     "shell.execute_reply.started": "2023-09-19T14:57:47.169979Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# PySCF IPU setup: use a single device per process.\n",
    "os.environ[\"JAX_IPU_DEVICE_COUNT\"] = \"1\"\n",
    "# JAX/XLA IPU compilation cache.\n",
    "os.environ['TF_POPLAR_FLAGS'] = \"\"\"\n",
    "  --executable_cache_path=/tmp/ipu-ef-cache\n",
    "\"\"\"\n",
    "\n",
    "# First import of JAX and TessellateIPU may take a few minutes...\n",
    "import jax\n",
    "import tessellate_ipu\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46c38d",
   "metadata": {},
   "source": [
    "# Create a DFT dataset using PySCF IPU\n",
    "\n",
    "In the following example, we use only a single IPU. Multiple IPUs can be used by simply launching a collection of PySCF IPU processes instead of a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea8a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T14:57:50.853563Z",
     "iopub.status.busy": "2023-09-19T14:57:50.853232Z",
     "iopub.status.idle": "2023-09-19T14:57:52.473054Z",
     "shell.execute_reply": "2023-09-19T14:57:52.472262Z",
     "shell.execute_reply.started": "2023-09-19T14:57:50.853542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Equivalent to command line:\n",
    "# python pyscf_ipu/dft.py  -generate  -save  -fname \"notebook_dataset\"\n",
    "#        -level 0  -plevel 0  -num_conformers 1000\n",
    "#        -gdb 9  -float32\n",
    "\n",
    "import time\n",
    "from pyscf_ipu.dft import get_args, process_args\n",
    "\n",
    "args = get_args([])\n",
    "args.backend = 'cpu'\n",
    "args.generate = True\n",
    "args.save = True\n",
    "args.fname = \"notebook_dataset\"\n",
    "\n",
    "args.level = 0\n",
    "args.plevel = 0\n",
    "\n",
    "args.float32 = True\n",
    "\n",
    "quick = True # Set to False to generate full dataset (takes some time)\n",
    "\n",
    "if quick:\n",
    "  args.id = 1\n",
    "  args.num_conformers = 32 # Set to 1000 for full dataset\n",
    "  args.limit = 33 # Comment out for full dataset\n",
    "else:\n",
    "  args.num_conformers = 1000\n",
    "\n",
    "process_args(args)\n",
    "\n",
    "# Load GDB09 data\n",
    "gdb = 'gdb11_size09'\n",
    "args.smiles = open(f\"../gdb/{gdb}_sorted.csv\", \"r\").read().split(\"\\n\")\n",
    "print(f'Loaded {len(args.smiles)} molecules from {gdb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41564018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T14:58:15.182876Z",
     "iopub.status.busy": "2023-09-19T14:58:15.182484Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "from pyscf_ipu.dft import angstrom_to_bohr, get_atom_string, jax_dft, recompute\n",
    "\n",
    "print(\"Length GDB: \", len(args.smiles))\n",
    "\n",
    "if args.limit != -1:\n",
    "    args.smiles = args.smiles[:args.limit]\n",
    "\n",
    "for i in range(int(args.id), min(int(args.id)+1000, len(args.smiles))):\n",
    "    smile = args.smiles[i]\n",
    "\n",
    "    print('Trying', smile)\n",
    "\n",
    "    b = Chem.MolFromSmiles(smile)\n",
    "    b = Chem.AddHs(b, explicitOnly=False)\n",
    "\n",
    "    e = Chem.AllChem.EmbedMolecule(b)\n",
    "    if e == -1:\n",
    "       print('Did not embed', b) \n",
    "       continue\n",
    "\n",
    "    locs = b.GetConformer().GetPositions() * angstrom_to_bohr\n",
    "    atoms = [atom.GetSymbol() for atom in b.GetAtoms()]\n",
    "    atom_string, string = get_atom_string(\" \".join(atoms), locs)\n",
    "\n",
    "    print('Conformer: ', string)\n",
    "    break\n",
    "\n",
    "recompute(args, None, 0, 0, our_fun=jax_dft, str=string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec0c9d",
   "metadata": {},
   "source": [
    "# Loading & visualizing generated data\n",
    "\n",
    "After the dataset has been created, we can load the data.\n",
    "(You may wish to spin up a new notebook, and view the data as \n",
    "it's being generated in this one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778133f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T14:56:25.989663Z",
     "iopub.status.idle": "2023-09-19T14:56:25.989906Z",
     "shell.execute_reply": "2023-09-19T14:56:25.989805Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd2293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:22:54.513539Z",
     "iopub.status.busy": "2023-09-19T11:22:54.513306Z",
     "iopub.status.idle": "2023-09-19T11:22:54.543391Z",
     "shell.execute_reply": "2023-09-19T11:22:54.542629Z",
     "shell.execute_reply.started": "2023-09-19T11:22:54.513520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output DFT dataset is a compressed CSV file.\n",
    "# NOTE: it may take a couple of minutes before the file is generated.\n",
    "rootpath = f'./data/generated/{args.fname}/'\n",
    "paths = sorted(os.listdir(rootpath), key=lambda x: os.path.getmtime(rootpath + x))\n",
    "filename = os.path.join(rootpath, paths[-1], \"data.csv\")\n",
    "\n",
    "df = pd.read_csv(filename, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e816e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:22:56.683299Z",
     "iopub.status.busy": "2023-09-19T11:22:56.682924Z",
     "iopub.status.idle": "2023-09-19T11:22:56.719309Z",
     "shell.execute_reply": "2023-09-19T11:22:56.718752Z",
     "shell.execute_reply.started": "2023-09-19T11:22:56.683279Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd76867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:23:14.674865Z",
     "iopub.status.busy": "2023-09-19T11:23:14.674473Z",
     "iopub.status.idle": "2023-09-19T11:23:14.695157Z",
     "shell.execute_reply": "2023-09-19T11:23:14.694107Z",
     "shell.execute_reply.started": "2023-09-19T11:23:14.674846Z"
    }
   },
   "outputs": [],
   "source": [
    "# HLgap data.\n",
    "df[\"hlgap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46e364-e56f-48b5-8be5-c913444e9c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
